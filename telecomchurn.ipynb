{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6603cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries for data processing and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 300)\n",
    "pd.set_option(\"display.max_rows\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0773102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the telecom churn dataset into a pandas DataFrame\n",
    "df_telecom = pd.read_csv(\"telecom_data_for_students.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a597f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at initial rows of the data\n",
    "df_telecom.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature type summary\n",
    "df_telecom.info(verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 99999 rows and 226 columns in the data. Lot of the columns are numeric type, but we need to inspect which are the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d8b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at data statistics\n",
    "df_telecom.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43806c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create backup of data\n",
    "original = df_telecom.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2643e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column name list by types of columns\n",
    "id_cols = ['mobile_number', 'circle_id']\n",
    "\n",
    "date_cols = ['last_date_of_month_6',\n",
    "             'last_date_of_month_7',\n",
    "             'last_date_of_month_8',\n",
    "             'last_date_of_month_9',\n",
    "             'date_of_last_rech_6',\n",
    "             'date_of_last_rech_7',\n",
    "             'date_of_last_rech_8',\n",
    "             'date_of_last_rech_9',\n",
    "             'date_of_last_rech_data_6',\n",
    "             'date_of_last_rech_data_7',\n",
    "             'date_of_last_rech_data_8',\n",
    "             'date_of_last_rech_data_9'\n",
    "            ]\n",
    "\n",
    "cat_cols =  ['night_pck_user_6',\n",
    "             'night_pck_user_7',\n",
    "             'night_pck_user_8',\n",
    "             'night_pck_user_9',\n",
    "             'fb_user_6',\n",
    "             'fb_user_7',\n",
    "             'fb_user_8',\n",
    "             'fb_user_9'\n",
    "            ]\n",
    "\n",
    "num_cols = [column for column in df_telecom.columns if column not in id_cols + date_cols + cat_cols]\n",
    "\n",
    "# print the number of columns in each list\n",
    "print(\"#ID cols: %d\\n#Date cols:%d\\n#Numeric cols:%d\\n#Category cols:%d\" % (len(id_cols), len(date_cols), len(num_cols), len(cat_cols)))\n",
    "\n",
    "# check if we have missed any column or not\n",
    "print(len(id_cols) + len(date_cols) + len(num_cols) + len(cat_cols) == df_telecom.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd6c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at missing value ratio in each column\n",
    "df_telecom.isnull().sum()*100/df_telecom.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# impute missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i) Imputing with zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d0c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some recharge columns have minimum value of 1 while some don't\n",
    "recharge_cols = ['total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8', 'total_rech_data_9',\n",
    "                 'count_rech_2g_6', 'count_rech_2g_7', 'count_rech_2g_8', 'count_rech_2g_9',\n",
    "                 'count_rech_3g_6', 'count_rech_3g_7', 'count_rech_3g_8', 'count_rech_3g_9',\n",
    "                 'max_rech_data_6', 'max_rech_data_7', 'max_rech_data_8', 'max_rech_data_9',\n",
    "                 'av_rech_amt_data_6', 'av_rech_amt_data_7', 'av_rech_amt_data_8', 'av_rech_amt_data_9',\n",
    "                 ]\n",
    "\n",
    "df_telecom[recharge_cols].describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044c70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is also observed that the recharge date and the recharge value are missing together which means the customer didn't recharge\n",
    "df_telecom.loc[df_telecom.total_rech_data_6.isnull() & df_telecom.date_of_last_rech_data_6.isnull(), [\"total_rech_data_6\", \"date_of_last_rech_data_6\"]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the recharge variables where minumum value is 1, we can impute missing values with zeroes since it means customer didn't recharge their numbere that month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada96b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of recharge columns where we will impute missing values with zeroes\n",
    "zero_impute = ['total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8', 'total_rech_data_9',\n",
    "        'av_rech_amt_data_6', 'av_rech_amt_data_7', 'av_rech_amt_data_8', 'av_rech_amt_data_9',\n",
    "        'max_rech_data_6', 'max_rech_data_7', 'max_rech_data_8', 'max_rech_data_9'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9f95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values with 0\n",
    "df_telecom[zero_impute] = df_telecom[zero_impute].apply(lambda x: x.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b46151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's make sure values are imputed correctly\n",
    "print(\"Missing value ratio:\\n\")\n",
    "print(df_telecom[zero_impute].isnull().sum()*100/df_telecom.shape[1])\n",
    "\n",
    "# summary\n",
    "print(\"\\n\\nSummary statistics\\n\")\n",
    "print(df_telecom[zero_impute].describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a7192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop id and date columns\n",
    "print(\"Shape before dropping: \", df_telecom.shape)\n",
    "df_telecom = df_telecom.drop(id_cols + date_cols, axis=1)\n",
    "print(\"Shape after dropping: \", df_telecom.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii) Replace NaN values in categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will replace missing values in the categorical values with '-1' where '-1' will be a new category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0133750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with '-1' in categorical columns\n",
    "df_telecom[cat_cols] = df_telecom[cat_cols].apply(lambda x: x.fillna(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value ratio\n",
    "print(\"Missing value ratio:\\n\")\n",
    "print(df_telecom[cat_cols].isnull().sum()*100/df_telecom.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii) Drop variables with more than a given threshold of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f13266",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_cols = df_telecom.shape[1]\n",
    "\n",
    "MISSING_THRESHOLD = 0.7\n",
    "\n",
    "include_cols = list(df_telecom.apply(lambda column: True if column.isnull().sum()/df_telecom.shape[0] < MISSING_THRESHOLD else False))\n",
    "\n",
    "drop_missing = pd.DataFrame({'features':df_telecom.columns , 'include': include_cols})\n",
    "drop_missing.loc[drop_missing.include == True,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81f175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "df_telecom = df_telecom.loc[:, include_cols]\n",
    "\n",
    "dropped_cols = df_telecom.shape[1] - initial_cols\n",
    "print(\"{0} columns dropped.\".format(dropped_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv) imputing using MICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install fancyimpute package using [this](https://github.com/iskandr/fancyimpute) link and following the install instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a6349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_telecom_cols = df_telecom.columns\n",
    "\n",
    "# using MICE technique to impute missing values in the rest of the columns\n",
    "from fancyimpute import MICE\n",
    "df_telecom_imputed = MICE(n_imputations=1).complete(df_telecom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5409be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert imputed numpy array to pandas dataframe\n",
    "df_telecom = pd.DataFrame(df_telecom_imputed, columns=df_telecom_cols)\n",
    "print(df_telecom.isnull().sum()*100/df_telecom.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter high-value customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate total data recharge amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total data recharge amount for June and July --> number of recharges * average recharge amount\n",
    "df_telecom['total_data_rech_6'] = df_telecom.total_rech_data_6 * df_telecom.av_rech_amt_data_6\n",
    "df_telecom['total_data_rech_7'] = df_telecom.total_rech_data_7 * df_telecom.av_rech_amt_data_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add total data recharge and total recharge to get total combined recharge amount for a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc0669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total recharge amount for June and July --> call recharge amount + data recharge amount\n",
    "df_telecom['amt_data_6'] = df_telecom.total_rech_amt_6 + df_telecom.total_data_rech_6\n",
    "df_telecom['amt_data_7'] = df_telecom.total_rech_amt_7 + df_telecom.total_data_rech_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4896e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average recharge done by customer in June and July\n",
    "df_telecom['av_amt_data_6_7'] = (df_telecom.amt_data_6 + df_telecom.amt_data_7)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1339da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the 70th percentile recharge amount\n",
    "print(\"Recharge amount at 70th percentile: {0}\".format(df_telecom.av_amt_data_6_7.quantile(0.7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc9bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only those customers who have recharged their mobiles with more than or equal to 70th percentile amount\n",
    "df_telecom_filtered = df_telecom.loc[df_telecom.av_amt_data_6_7 >= df_telecom.av_amt_data_6_7.quantile(0.7), :]\n",
    "df_telecom_filtered = df_telecom_filtered.reset_index(drop=True)\n",
    "df_telecom_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacdaa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables created to filter high-value customers\n",
    "df_telecom_filtered = df_telecom_filtered.drop(['total_data_rech_6', 'total_data_rech_7',\n",
    "                                      'amt_data_6', 'amt_data_7', 'av_amt_data_6_7'], axis=1)\n",
    "df_telecom_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're left with 30,001 rows after selecting the customers who have provided recharge value of more than or equal to the recharge value of the 70th percentile customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# derive churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35611dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total incoming and outgoing minutes of usage\n",
    "df_telecom_filtered['total_calls_mou_9'] = df_telecom_filtered.total_ic_mou_9 + df_telecom_filtered.total_og_mou_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc95c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate 2g and 3g data consumption\n",
    "df_telecom_filtered['total_internet_mb_9'] =  df_telecom_filtered.vol_2g_mb_9 + df_telecom_filtered.vol_3g_mb_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879dad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df_telecom variable: those who have not used either calls or internet in the month of September are customers who have df_telecomed\n",
    "\n",
    "# 0 - not df_telecom, 1 - df_telecom\n",
    "df_telecom_filtered['df_telecom'] = df_telecom_filtered.apply(lambda row: 1 if (row.total_calls_mou_9 == 0 and row.total_internet_mb_9 == 0) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete derived variables\n",
    "df_telecom_filtered = df_telecom_filtered.drop(['total_calls_mou_9', 'total_internet_mb_9'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758ae6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type to category\n",
    "df_telecom_filtered.df_telecom = df_telecom_filtered.df_telecom.astype(\"category\")\n",
    "\n",
    "# print df_telecom ratio\n",
    "print(\"Churn Ratio:\")\n",
    "print(df_telecom_filtered.df_telecom.value_counts()*100/df_telecom_filtered.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate difference between 8th and previous months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's derive some variables. The most important feature, in this situation, can be the difference between the 8th month and the previous months. The difference can be in patterns such as usage difference or recharge value difference. Let's calculate difference variable as the difference between 8th month and the average of 6th and 7th month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13c94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_telecom_filtered['arpu_diff'] = df_telecom_filtered.arpu_8 - ((df_telecom_filtered.arpu_6 + df_telecom_filtered.arpu_7)/2)\n",
    "\n",
    "df_telecom_filtered['onnet_mou_diff'] = df_telecom_filtered.onnet_mou_8 - ((df_telecom_filtered.onnet_mou_6 + df_telecom_filtered.onnet_mou_7)/2)\n",
    "\n",
    "df_telecom_filtered['offnet_mou_diff'] = df_telecom_filtered.offnet_mou_8 - ((df_telecom_filtered.offnet_mou_6 + df_telecom_filtered.offnet_mou_7)/2)\n",
    "\n",
    "df_telecom_filtered['roam_ic_mou_diff'] = df_telecom_filtered.roam_ic_mou_8 - ((df_telecom_filtered.roam_ic_mou_6 + df_telecom_filtered.roam_ic_mou_7)/2)\n",
    "\n",
    "df_telecom_filtered['roam_og_mou_diff'] = df_telecom_filtered.roam_og_mou_8 - ((df_telecom_filtered.roam_og_mou_6 + df_telecom_filtered.roam_og_mou_7)/2)\n",
    "\n",
    "df_telecom_filtered['loc_og_mou_diff'] = df_telecom_filtered.loc_og_mou_8 - ((df_telecom_filtered.loc_og_mou_6 + df_telecom_filtered.loc_og_mou_7)/2)\n",
    "\n",
    "df_telecom_filtered['std_og_mou_diff'] = df_telecom_filtered.std_og_mou_8 - ((df_telecom_filtered.std_og_mou_6 + df_telecom_filtered.std_og_mou_7)/2)\n",
    "\n",
    "df_telecom_filtered['isd_og_mou_diff'] = df_telecom_filtered.isd_og_mou_8 - ((df_telecom_filtered.isd_og_mou_6 + df_telecom_filtered.isd_og_mou_7)/2)\n",
    "\n",
    "df_telecom_filtered['spl_og_mou_diff'] = df_telecom_filtered.spl_og_mou_8 - ((df_telecom_filtered.spl_og_mou_6 + df_telecom_filtered.spl_og_mou_7)/2)\n",
    "\n",
    "df_telecom_filtered['total_og_mou_diff'] = df_telecom_filtered.total_og_mou_8 - ((df_telecom_filtered.total_og_mou_6 + df_telecom_filtered.total_og_mou_7)/2)\n",
    "\n",
    "df_telecom_filtered['loc_ic_mou_diff'] = df_telecom_filtered.loc_ic_mou_8 - ((df_telecom_filtered.loc_ic_mou_6 + df_telecom_filtered.loc_ic_mou_7)/2)\n",
    "\n",
    "df_telecom_filtered['std_ic_mou_diff'] = df_telecom_filtered.std_ic_mou_8 - ((df_telecom_filtered.std_ic_mou_6 + df_telecom_filtered.std_ic_mou_7)/2)\n",
    "\n",
    "df_telecom_filtered['isd_ic_mou_diff'] = df_telecom_filtered.isd_ic_mou_8 - ((df_telecom_filtered.isd_ic_mou_6 + df_telecom_filtered.isd_ic_mou_7)/2)\n",
    "\n",
    "df_telecom_filtered['spl_ic_mou_diff'] = df_telecom_filtered.spl_ic_mou_8 - ((df_telecom_filtered.spl_ic_mou_6 + df_telecom_filtered.spl_ic_mou_7)/2)\n",
    "\n",
    "df_telecom_filtered['total_ic_mou_diff'] = df_telecom_filtered.total_ic_mou_8 - ((df_telecom_filtered.total_ic_mou_6 + df_telecom_filtered.total_ic_mou_7)/2)\n",
    "\n",
    "df_telecom_filtered['total_rech_num_diff'] = df_telecom_filtered.total_rech_num_8 - ((df_telecom_filtered.total_rech_num_6 + df_telecom_filtered.total_rech_num_7)/2)\n",
    "\n",
    "df_telecom_filtered['total_rech_amt_diff'] = df_telecom_filtered.total_rech_amt_8 - ((df_telecom_filtered.total_rech_amt_6 + df_telecom_filtered.total_rech_amt_7)/2)\n",
    "\n",
    "df_telecom_filtered['max_rech_amt_diff'] = df_telecom_filtered.max_rech_amt_8 - ((df_telecom_filtered.max_rech_amt_6 + df_telecom_filtered.max_rech_amt_7)/2)\n",
    "\n",
    "df_telecom_filtered['total_rech_data_diff'] = df_telecom_filtered.total_rech_data_8 - ((df_telecom_filtered.total_rech_data_6 + df_telecom_filtered.total_rech_data_7)/2)\n",
    "\n",
    "df_telecom_filtered['max_rech_data_diff'] = df_telecom_filtered.max_rech_data_8 - ((df_telecom_filtered.max_rech_data_6 + df_telecom_filtered.max_rech_data_7)/2)\n",
    "\n",
    "df_telecom_filtered['av_rech_amt_data_diff'] = df_telecom_filtered.av_rech_amt_data_8 - ((df_telecom_filtered.av_rech_amt_data_6 + df_telecom_filtered.av_rech_amt_data_7)/2)\n",
    "\n",
    "df_telecom_filtered['vol_2g_mb_diff'] = df_telecom_filtered.vol_2g_mb_8 - ((df_telecom_filtered.vol_2g_mb_6 + df_telecom_filtered.vol_2g_mb_7)/2)\n",
    "\n",
    "df_telecom_filtered['vol_3g_mb_diff'] = df_telecom_filtered.vol_3g_mb_8 - ((df_telecom_filtered.vol_3g_mb_6 + df_telecom_filtered.vol_3g_mb_7)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8beabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at summary of one of the difference variables\n",
    "df_telecom_filtered['total_og_mou_diff'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete columns that belong to the churn month (9th month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all variables relating to 9th month\n",
    "df_telecom_filtered = df_telecom_filtered.filter(regex='[^9]$', axis=1)\n",
    "df_telecom_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6fba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all names that end with 9\n",
    "col_9_names = df_telecom.filter(regex='9$', axis=1).columns\n",
    "\n",
    "# update num_cols and cat_cols column name list\n",
    "cat_cols = [col for col in cat_cols if col not in col_9_names]\n",
    "cat_cols.append('df_telecom')\n",
    "num_cols = [col for col in df_telecom_filtered.columns if col not in cat_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab54a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change columns types\n",
    "df_telecom_filtered[num_cols] = df_telecom_filtered[num_cols].apply(pd.to_numeric)\n",
    "df_telecom_filtered[cat_cols] = df_telecom_filtered[cat_cols].apply(lambda column: column.astype(\"category\"), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d69d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plotting functions\n",
    "def data_type(variable):\n",
    "    if variable.dtype == np.int64 or variable.dtype == np.float64:\n",
    "        return 'numerical'\n",
    "    elif variable.dtype == 'category':\n",
    "        return 'categorical'\n",
    "    \n",
    "def univariate(variable, stats=True):\n",
    "    \n",
    "    if data_type(variable) == 'numerical':\n",
    "        sns.distplot(variable)\n",
    "        if stats == True:\n",
    "            print(variable.describe())\n",
    "    \n",
    "    elif data_type(variable) == 'categorical':\n",
    "        sns.countplot(variable)\n",
    "        if stats == True:\n",
    "            print(variable.value_counts())\n",
    "            \n",
    "    else:\n",
    "        print(\"Invalid variable passed: either pass a numeric variable or a categorical vairable.\")\n",
    "        \n",
    "def bivariate(var1, var2):\n",
    "    if data_type(var1) == 'numerical' and data_type(var2) == 'numerical':\n",
    "        sns.regplot(var1, var2)\n",
    "    elif (data_type(var1) == 'categorical' and data_type(var2) == 'numerical') or (data_type(var1) == 'numerical' and data_type(var2) == 'categorical'):        \n",
    "        sns.boxplot(var1, var2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(df_telecom.arpu_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80fc1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(df_telecom.loc_og_t2o_mou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff95180",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(df_telecom.std_og_t2o_mou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46bd92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(df_telecom.onnet_mou_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60aac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(df_telecom.offnet_mou_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables are very **skewed** towards the left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate(df_telecom_filtered.df_telecom, df_telecom_filtered.aon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b967883",
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate(df_telecom_filtered.sep_vbc_3g, df_telecom_filtered.df_telecom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e14b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate(df_telecom_filtered.spl_og_mou_8, df_telecom_filtered.df_telecom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee5f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_telecom_filtered.df_telecom, df_telecom_filtered.night_pck_user_8, normalize='columns')*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b46d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_telecom_filtered.df_telecom, df_telecom_filtered.sachet_3g_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cap outliers in all numeric variables with k-sigma technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a48819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_outliers(array, k=3):\n",
    "    upper_limit = array.mean() + k*array.std()\n",
    "    lower_limit = array.mean() - k*array.std()\n",
    "    array[array<lower_limit] = lower_limit\n",
    "    array[array>upper_limit] = upper_limit\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of capping\n",
    "sample_array = list(range(100))\n",
    "\n",
    "# add outliers to the data\n",
    "sample_array[0] = -9999\n",
    "sample_array[99] = 9999\n",
    "\n",
    "# cap outliers\n",
    "sample_array = np.array(sample_array)\n",
    "print(\"Array after capping outliers: \\n\", cap_outliers(sample_array, k=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122bd141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap outliers in the numeric columns\n",
    "df_telecom_filtered[num_cols] = df_telecom_filtered[num_cols].apply(cap_outliers, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i) Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b6362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.metrics import sensitivity_specificity_support\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed1b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change df_telecom to numeric\n",
    "df_telecom_filtered['df_telecom'] = pd.to_numeric(df_telecom_filtered['df_telecom'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d961f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into train and test\n",
    "X = df_telecom_filtered.drop(\"df_telecom\", axis = 1)\n",
    "y = df_telecom_filtered.df_telecom\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 4, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a06361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print shapes of train and test sets\n",
    "X_train.shape\n",
    "y_train.shape\n",
    "X_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfedfaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# aggregate the categorical variables\n",
    "train.groupby('night_pck_user_6').df_telecom.mean()\n",
    "train.groupby('night_pck_user_7').df_telecom.mean()\n",
    "train.groupby('night_pck_user_8').df_telecom.mean()\n",
    "train.groupby('fb_user_6').df_telecom.mean()\n",
    "train.groupby('fb_user_7').df_telecom.mean()\n",
    "train.groupby('fb_user_8').df_telecom.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a16a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace categories with aggregated values in each categorical column\n",
    "mapping = {'night_pck_user_6' : {-1: 0.099165, 0: 0.066797, 1: 0.087838},\n",
    "           'night_pck_user_7' : {-1: 0.115746, 0: 0.055494, 1: 0.051282},\n",
    "           'night_pck_user_8' : {-1: 0.141108, 0: 0.029023, 1: 0.016194},\n",
    "           'fb_user_6'        : {-1: 0.099165, 0: 0.069460, 1: 0.067124},\n",
    "           'fb_user_7'        : {-1: 0.115746, 0: 0.059305, 1: 0.055082},\n",
    "           'fb_user_8'        : {-1: 0.141108, 0: 0.066887, 1: 0.024463}\n",
    "          }\n",
    "X_train.replace(mapping, inplace = True)\n",
    "X_test.replace(mapping, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data type of categorical columns - make sure they are numeric\n",
    "X_train[[col for col in cat_cols if col not in ['df_telecom']]].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a98e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pca to train data\n",
    "pca = Pipeline([('scaler', StandardScaler()), ('pca', PCA())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_train)\n",
    "df_telecom_pca = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee25379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pca model from pipeline\n",
    "pca = pca.named_steps['pca']\n",
    "\n",
    "# look at explainded variance of PCA components\n",
    "print(pd.Series(np.round(pca.explained_variance_ratio_.cumsum(), 4)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~ 60 components explain 90% variance\n",
    "\n",
    "~ 80 components explain 95% variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77556f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature variance\n",
    "features = range(pca.n_components_)\n",
    "cumulative_variance = np.round(np.cumsum(pca.explained_variance_ratio_)*100, decimals=4)\n",
    "plt.figure(figsize=(175/20,100/20)) # 100 elements on y-axis; 175 elements on x-axis; 20 is normalising factor\n",
    "plt.plot(cumulative_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c2bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "PCA_VARS = 60\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         (\"pca\", PCA(n_components=PCA_VARS)),\n",
    "         (\"logistic\", LogisticRegression(class_weight='balanced'))\n",
    "        ]\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# check score on train data\n",
    "pipeline.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb679ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict df_telecom on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# create onfusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# check sensitivity and specificity\n",
    "sensitivity, specificity, _ = sensitivity_specificity_support(y_test, y_pred, average='binary')\n",
    "print(\"Sensitivity: \\t\", round(sensitivity, 2), \"\\n\", \"Specificity: \\t\", round(specificity, 2), sep='')\n",
    "\n",
    "# check area under curve\n",
    "y_pred_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC:    \\t\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - PCA and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab66bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class imbalance\n",
    "y_train.value_counts()/y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f247f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA()\n",
    "\n",
    "# logistic regression - the class weight is used to handle class imbalance - it adjusts the cost function\n",
    "logistic = LogisticRegression(class_weight={0:0.1, 1: 0.9})\n",
    "\n",
    "# create pipeline\n",
    "steps = [(\"scaler\", StandardScaler()), \n",
    "         (\"pca\", pca),\n",
    "         (\"logistic\", logistic)\n",
    "        ]\n",
    "\n",
    "# compile pipeline\n",
    "pca_logistic = Pipeline(steps)\n",
    "\n",
    "# hyperparameter space\n",
    "params = {'pca__n_components': [60, 80], 'logistic__C': [0.1, 0.5, 1, 2, 3, 4, 5, 10], 'logistic__penalty': ['l1', 'l2']}\n",
    "\n",
    "# create 5 folds\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 4)\n",
    "\n",
    "# create gridsearch object\n",
    "model = GridSearchCV(estimator=pca_logistic, cv=folds, param_grid=params, scoring='roc_auc', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation results\n",
    "pd.DataFrame(model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best hyperparameters\n",
    "print(\"Best AUC: \", model.best_score_)\n",
    "print(\"Best hyperparameters: \", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict df_telecom on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# create onfusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# check sensitivity and specificity\n",
    "sensitivity, specificity, _ = sensitivity_specificity_support(y_test, y_pred, average='binary')\n",
    "print(\"Sensitivity: \\t\", round(sensitivity, 2), \"\\n\", \"Specificity: \\t\", round(specificity, 2), sep='')\n",
    "\n",
    "# check area under curve\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC:    \\t\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest - the class weight is used to handle class imbalance - it adjusts the cost function\n",
    "forest = RandomForestClassifier(class_weight={0:0.1, 1: 0.9}, n_jobs = -1)\n",
    "\n",
    "# hyperparameter space\n",
    "params = {\"criterion\": ['gini', 'entropy'], \"max_features\": ['auto', 0.4]}\n",
    "\n",
    "# create 5 folds\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 4)\n",
    "\n",
    "# create gridsearch object\n",
    "model = GridSearchCV(estimator=forest, cv=folds, param_grid=params, scoring='roc_auc', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319c6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best hyperparameters\n",
    "print(\"Best AUC: \", model.best_score_)\n",
    "print(\"Best hyperparameters: \", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee5d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict df_telecom on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# create onfusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# check sensitivity and specificity\n",
    "sensitivity, specificity, _ = sensitivity_specificity_support(y_test, y_pred, average='binary')\n",
    "print(\"Sensitivity: \\t\", round(sensitivity, 2), \"\\n\", \"Specificity: \\t\", round(specificity, 2), sep='')\n",
    "\n",
    "# check area under curve\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC:    \\t\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poor sensitivity. The best model is PCA along with Logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii) Choosing best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4cbfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a random forest model on train data\n",
    "max_features = int(round(np.sqrt(X_train.shape[1])))    # number of variables to consider to split each node\n",
    "print(max_features)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_features=max_features, class_weight={0:0.1, 1: 0.9}, oob_score=True, random_state=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc8302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34985fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOB score\n",
    "rf_model.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b833257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict df_telecom on test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# create onfusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# check sensitivity and specificity\n",
    "sensitivity, specificity, _ = sensitivity_specificity_support(y_test, y_pred, average='binary')\n",
    "print(\"Sensitivity: \\t\", round(sensitivity, 2), \"\\n\", \"Specificity: \\t\", round(specificity, 2), sep='')\n",
    "\n",
    "# check area under curve\n",
    "y_pred_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "print(\"ROC:    \\t\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors\n",
    "features = df_telecom_filtered.drop('df_telecom', axis=1).columns\n",
    "\n",
    "# feature_importance\n",
    "importance = rf_model.feature_importances_\n",
    "\n",
    "# create dataframe\n",
    "feature_importance = pd.DataFrame({'variables': features, 'importance_percentage': importance*100})\n",
    "feature_importance = feature_importance[['variables', 'importance_percentage']]\n",
    "\n",
    "# sort features\n",
    "feature_importance = feature_importance.sort_values('importance_percentage', ascending=False).reset_index(drop=True)\n",
    "print(\"Sum of importance=\", feature_importance.importance_percentage.sum())\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting top 30 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbaa361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract top 'n' features\n",
    "top_n = 30\n",
    "top_features = feature_importance.variables[0:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9285db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature correlation\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] =(10,10)\n",
    "mycmap = sns.diverging_palette(199, 359, s=99, center=\"light\", as_cmap=True)\n",
    "sns.heatmap(data=X_train[top_features].corr(), center=0.0, cmap=mycmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d0002",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = ['total_ic_mou_8', 'total_rech_amt_diff', 'total_og_mou_8', 'arpu_8', 'roam_ic_mou_8', 'roam_og_mou_8', \n",
    "                'std_ic_mou_8', 'av_rech_amt_data_8', 'std_og_mou_8']\n",
    "X_train = X_train[top_features]\n",
    "X_test = X_test[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b171ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "steps = [('scaler', StandardScaler()), \n",
    "         (\"logistic\", LogisticRegression(class_weight={0:0.1, 1:0.9}))\n",
    "        ]\n",
    "\n",
    "# compile pipeline\n",
    "logistic = Pipeline(steps)\n",
    "\n",
    "# hyperparameter space\n",
    "params = {'logistic__C': [0.1, 0.5, 1, 2, 3, 4, 5, 10], 'logistic__penalty': ['l1', 'l2']}\n",
    "\n",
    "# create 5 folds\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 4)\n",
    "\n",
    "# create gridsearch object\n",
    "model = GridSearchCV(estimator=logistic, cv=folds, param_grid=params, scoring='roc_auc', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5636f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54976ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best hyperparameters\n",
    "print(\"Best AUC: \", model.best_score_)\n",
    "print(\"Best hyperparameters: \", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb31ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict df_telecom on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# create onfusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# check sensitivity and specificity\n",
    "sensitivity, specificity, _ = sensitivity_specificity_support(y_test, y_pred, average='binary')\n",
    "print(\"Sensitivity: \\t\", round(sensitivity, 2), \"\\n\", \"Specificity: \\t\", round(specificity, 2), sep='')\n",
    "\n",
    "# check area under curve\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "print(\"ROC:    \\t\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the intercept and the coefficients from the logistic model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfeb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = model.best_estimator_.named_steps['logistic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d915a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intercept\n",
    "intercept_df = pd.DataFrame(logistic_model.intercept_.reshape((1,1)), columns = ['intercept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2570cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients\n",
    "coefficients = logistic_model.coef_.reshape((9, 1)).tolist()\n",
    "coefficients = [val for sublist in coefficients for val in sublist]\n",
    "coefficients = [round(coefficient, 3) for coefficient in coefficients]\n",
    "\n",
    "logistic_features = list(X_train.columns)\n",
    "coefficients_df = pd.DataFrame(logistic_model.coef_, columns=logistic_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c0e184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dataframes\n",
    "coefficients = pd.concat([intercept_df, coefficients_df], axis=1)\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Insights\n",
    "\n",
    "* Telecom company needs to pay attention to the roaming rates. They need to provide good offers to the customers who are using services from a roaming zone.\n",
    "* The company needs to focus on the STD and ISD rates. Perhaps, the rates are too high. Provide them with some kind of STD and ISD packages.\n",
    "* To look into both of the issues stated above, it is desired that the telecom company collects customer query and complaint data and work on their services according to the needs of customers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455de00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
